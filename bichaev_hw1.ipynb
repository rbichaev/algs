{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 16 марта 2020, 08:30 \n",
    "\n",
    "**Штраф за опоздание:** по 1 баллу за 24 часа задержки. Через 5 дней домашнее задание сгорает.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла\n",
    "Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "\n",
    "[ML0220, Задание 1] Фамилия Имя.\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Штрафные баллы:**\n",
    "\n",
    "1. Отсутствие фамилии в имени скрипта (скрипт должен называться по аналогии со stroykova_hw1.ipynb) -0.5 баллов\n",
    "2. Все строчки должны быть выполнены. Нужно, чтобы output команды можно было увидеть уже в git'е. В противном случае -0.5 баллов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Задание 1 (1 балл)\n",
    "Реализовать KNN в классе MyKNeighborsClassifier (обязательное условие: точность не ниже sklearn реализации)\n",
    "Разберитесь самостоятельно, какая мера расстояния используется в KNeighborsClassifier дефолтно и реализуйте свой алгоритм именно с этой мерой. \n",
    "Для подсчета расстояний можно использовать функции [отсюда](https://docs.scipy.org/doc/scipy/reference/spatial.distance.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "\n",
    "class MyKNeighborsClassifier(BaseEstimator):\n",
    "    \n",
    "    def __init__(self, n_neighbors, algorithm='brute', metric='euclidean'):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        \n",
    "        if algorithm != \"brute\" and algorithm != \"kd_tree\":\n",
    "            print(\"Error while creating class! I don't know this algorithm! Try another one!\")\n",
    "            exit(1)\n",
    "            \n",
    "        self.algorithm = algorithm\n",
    "        self.metric = metric\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.X_train = X\n",
    "        self.y_train = y\n",
    "        \n",
    "        if self.algorithm == \"kd_tree\":\n",
    "            self.kdtree = KDTree(self.X_train)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        if self.algorithm == \"brute\":        \n",
    "            distances = pairwise_distances(X, self.X_train, self.metric)\n",
    "            k_nearest_inds = np.argpartition(distances, self.n_neighbors, axis = 1)[:, :self.n_neighbors]\n",
    "            y_train_nearest = self.y_train[k_nearest_inds]\n",
    "            y_pred = mode(y_train_nearest, axis = 1)[0]\n",
    "            \n",
    "        if self.algorithm == \"kd_tree\":\n",
    "            nearest_dist, nearest_inds = self.kdtree.query(X, k=self.n_neighbors)\n",
    "            y_train_nearest = self.y_train[nearest_inds]\n",
    "            y_pred = mode(y_train_nearest, axis = 1)[0]\n",
    "        \n",
    "        return y_pred.reshape(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IRIS**\n",
    "\n",
    "В библиотеке scikit-learn есть несколько датасетов из коробки. Один из них [Ирисы Фишера](https://ru.wikipedia.org/wiki/%D0%98%D1%80%D0%B8%D1%81%D1%8B_%D0%A4%D0%B8%D1%88%D0%B5%D1%80%D0%B0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.1, stratify=iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=2, algorithm='brute')\n",
    "my_clf = MyKNeighborsClassifier(n_neighbors=2, algorithm='brute')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_pred = clf.predict(X_test)\n",
    "my_clf_pred = my_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_pred = clf.predict(X_test)\n",
    "my_clf_pred = my_clf.predict(X_test)\n",
    "assert abs( accuracy_score(y_test, my_clf_pred) -  accuracy_score(y_test, sklearn_pred ) )<0.005, \"Score must be simillar\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2 (0.5 балла)**\n",
    "\n",
    "Давайте попробуем добиться скорости работы на fit, predict сравнимой со sklearn для iris. Допускается замедление не более чем в 2 раза. \n",
    "Для этого используем numpy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.16 ms, sys: 262 µs, total: 1.43 ms\n",
      "Wall time: 1.05 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='brute', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1 µs, total: 6 µs\n",
      "Wall time: 9.3 µs\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 209 µs, sys: 4.19 ms, total: 4.4 ms\n",
      "Wall time: 4.02 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 1, 0, 0, 2, 1, 1, 2, 0, 1, 2, 0, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.34 ms, sys: 303 µs, total: 1.64 ms\n",
      "Wall time: 1.29 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 1, 0, 0, 2, 1, 1, 2, 0, 1, 2, 0, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Задание 3 (1 балл)\n",
    "Добавьте algorithm='kd_tree' в реализацию KNN (использовать KDTree из sklearn.neighbors). Необходимо добиться скорости работы на fit,  predict сравнимой со sklearn для iris. Допускается замедление не более чем в 2 раза. \n",
    "Для этого используем numpy. Точность не должна уступать значению KNN из sklearn. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=2, algorithm='kd_tree')\n",
    "my_clf = MyKNeighborsClassifier(n_neighbors=2, algorithm='kd_tree')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.1, stratify=iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.76 ms, sys: 396 µs, total: 2.15 ms\n",
      "Wall time: 23.6 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='kd_tree', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=2, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 165 µs, sys: 37 µs, total: 202 µs\n",
      "Wall time: 180 µs\n"
     ]
    }
   ],
   "source": [
    "%time my_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.88 ms, sys: 170 µs, total: 5.05 ms\n",
      "Wall time: 3.94 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 0, 2, 0, 0, 2, 1, 0, 0, 1, 2, 1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.04 ms, sys: 457 µs, total: 2.5 ms\n",
      "Wall time: 1.95 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 0, 2, 0, 0, 2, 1, 0, 0, 1, 2, 1, 1])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time my_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_pred = clf.predict(X_test)\n",
    "my_clf_pred = my_clf.predict(X_test)\n",
    "assert abs( accuracy_score(y_test, my_clf_pred) -  accuracy_score(y_test, sklearn_pred ) )<0.005, \"Score must be simillar\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 4 (2.5 балла)**\n",
    "\n",
    "Рассмотрим новый датасет 20 newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups(subset='train',remove=['headers','footers', 'quotes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = newsgroups['data']\n",
    "target = newsgroups['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразуйте текстовые данные из data с помощью [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html). Словарь можно ограничить по частотности."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<11314x10000 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 924130 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cntvctr = CountVectorizer(max_features = 10000)\n",
    "data_vect = cntvctr.fit_transform(data)\n",
    "data_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Так мы получили векторное представление наших текстов. Значит можно приступать к задаче обучения модели*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте разбиение выборки для кросс-валидации на 3 фолдах. Разрешено использовать sklearn.cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.1824.\n",
      "Accuracy score is 0.1848.\n",
      "Accuracy score is 0.1851.\n",
      "\n",
      "Mean accuracy on 3 folds is 0.1841.\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=3)\n",
    "mclsf = MyKNeighborsClassifier(n_neighbors=2, algorithm='brute')\n",
    "accuracy_mean = 0\n",
    "\n",
    "for train_index, val_index in kf.split(data_vect):\n",
    "    data_vect_train, data_vect_val = data_vect[train_index], data_vect[val_index]\n",
    "    target_train, target_val = target[train_index], target[val_index]\n",
    "    mclsf.fit(data_vect_train, target_train)\n",
    "    pred = mclsf.predict(data_vect_val)\n",
    "    acc = accuracy_score(pred, target_val)\n",
    "    accuracy_mean += acc\n",
    "    print(\"Accuracy score is %.4f.\" % acc)\n",
    "    \n",
    "accuracy_mean /= 3\n",
    "print(\"\\nMean accuracy on 3 folds is %.4f.\" % accuracy_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Напишите метод, позволяющий найти оптимальное количество ближайших соседей(дающее максимальную точность в среднем на валидации на 3 фолдах).\n",
    "Постройте график зависимости средней точности от количества соседей. Можно рассмотреть число соседей от 1 до 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean accuracy for 1 neighbors is 0.2047.\n",
      "Mean accuracy for 2 neighbors is 0.1841.\n",
      "Mean accuracy for 3 neighbors is 0.1843.\n",
      "Mean accuracy for 4 neighbors is 0.1815.\n",
      "Mean accuracy for 5 neighbors is 0.1853.\n",
      "Mean accuracy for 6 neighbors is 0.1837.\n",
      "Mean accuracy for 7 neighbors is 0.1853.\n",
      "Mean accuracy for 8 neighbors is 0.1903.\n",
      "Mean accuracy for 9 neighbors is 0.1915.\n",
      "Mean accuracy for 10 neighbors is 0.1930.\n",
      "\n",
      "Best number of neighbors is 1.\n"
     ]
    }
   ],
   "source": [
    "def get_mean_acc(n_neighbors):\n",
    "    kf = KFold(n_splits=3)\n",
    "    mclsf = MyKNeighborsClassifier(n_neighbors=n_neighbors, algorithm='brute')\n",
    "    accuracy_mean = 0\n",
    "\n",
    "    for train_index, val_index in kf.split(data_vect):\n",
    "        data_vect_train, data_vect_val = data_vect[train_index], data_vect[val_index]\n",
    "        target_train, target_val = target[train_index], target[val_index]\n",
    "        mclsf.fit(data_vect_train, target_train)\n",
    "        pred = mclsf.predict(data_vect_val)\n",
    "        acc = accuracy_score(pred, target_val)\n",
    "        accuracy_mean += acc\n",
    "    \n",
    "    accuracy_mean /= 3\n",
    "    return accuracy_mean\n",
    "\n",
    "def get_best_n_neighbors():\n",
    "    means = []\n",
    "    for i in range(1, 11):\n",
    "        acc_mean = get_mean_acc(i)\n",
    "        print(\"Mean accuracy for %i neighbors is %.4f.\" % (i, acc_mean))\n",
    "        means.append(acc_mean)\n",
    "    return np.argmax(means) + 1\n",
    "\n",
    "best_number = get_best_n_neighbors()\n",
    "print(\"\\nBest number of neighbors is %i.\" % best_number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как изменится качество на валидации, если:\n",
    "\n",
    "1. Используется косинусная метрика вместо евклидовой.\n",
    "2. К текстам применяется TfIdf векторизацию( sklearn.feature_extraction.text.TfidfVectorizer)\n",
    "\n",
    "Сравните модели, выберите лучшую."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.2752.\n",
      "Accuracy score is 0.2636.\n",
      "Accuracy score is 0.2766.\n",
      "\n",
      "Mean accuracy on 3 folds is 0.2718.\n"
     ]
    }
   ],
   "source": [
    "# сначала попробуем использовать только косинусную метрику\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "mclsf = MyKNeighborsClassifier(n_neighbors=2, algorithm='brute', metric='cosine')\n",
    "accuracy_mean = 0\n",
    "\n",
    "for train_index, val_index in kf.split(data_vect):\n",
    "    data_vect_train, data_vect_val = data_vect[train_index], data_vect[val_index]\n",
    "    target_train, target_val = target[train_index], target[val_index]\n",
    "    mclsf.fit(data_vect_train, target_train)\n",
    "    pred = mclsf.predict(data_vect_val)\n",
    "    acc = accuracy_score(pred, target_val)\n",
    "    accuracy_mean += acc\n",
    "    print(\"Accuracy score is %.4f.\" % acc)\n",
    "    \n",
    "accuracy_mean /= 3\n",
    "print(\"\\nMean accuracy on 3 folds is %.4f.\" % accuracy_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features = 10000)\n",
    "data_tfidf = tfidf.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score is 0.5427.\n",
      "Accuracy score is 0.5338.\n",
      "Accuracy score is 0.5444.\n",
      "\n",
      "Mean accuracy on 3 folds is 0.5403.\n"
     ]
    }
   ],
   "source": [
    "# теперь попробуем совместить косинусную метрику и tfidf\n",
    "\n",
    "kf = KFold(n_splits=3)\n",
    "mclsf = MyKNeighborsClassifier(n_neighbors=2, algorithm='brute', metric='cosine')\n",
    "accuracy_mean = 0\n",
    "\n",
    "for train_index, val_index in kf.split(data_tfidf):\n",
    "    data_tfidf_train, data_tfidf_val = data_tfidf[train_index], data_tfidf[val_index]\n",
    "    target_train, target_val = target[train_index], target[val_index]\n",
    "    mclsf.fit(data_tfidf_train, target_train)\n",
    "    pred = mclsf.predict(data_tfidf_val)\n",
    "    acc = accuracy_score(pred, target_val)\n",
    "    accuracy_mean += acc\n",
    "    print(\"Accuracy score is %.4f.\" % acc)\n",
    "    \n",
    "accuracy_mean /= 3\n",
    "print(\"\\nMean accuracy on 3 folds is %.4f.\" % accuracy_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим  теперь test  часть нашей выборки и преобразуем её аналогично с train частью. Не забудьте, что наборы слов в train и test части могут отличаться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsgroups = fetch_20newsgroups(subset='test',remove=['headers','footers', 'quotes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = newsgroups['data']\n",
    "test_target = newsgroups['target']\n",
    "newgroups_tfidf = tfidf.transform(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценим точность вашей лучшей модели на test части датасета. Отличается ли оно от кросс-валидации? Попробуйте сделать выводы, почему отличается качество."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4629580456718003"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict = mclsf.predict(newgroups_tfidf)\n",
    "accuracy_score(test_predict, test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Качество отличается в худшую сторону. Возможная причина - наличие слов, которые отсутствовали в train датасете."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
